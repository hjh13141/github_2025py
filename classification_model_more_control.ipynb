{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对应`tf.kears` 版本的03，在训练过程中加入更多的控制\n",
    "\n",
    "1. 训练中保存/保存最好的模型\n",
    "2. 早停 \n",
    "3. 训练过程可视化\n",
    "\n",
    "<font color=\"red\">注</font>: 使用 tensorboard 可视化需要安装 tensorflow (TensorBoard依赖于tensorflow库，可以任意安装tensorflow的gpu/cpu版本)\n",
    "\n",
    "```shell\n",
    "pip install tensorflow\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T14:27:35.227931Z",
     "start_time": "2025-02-21T14:26:53.039039Z"
    }
   },
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, torch:\n",
    "    print(module.__name__, module.__version__)\n",
    "    \n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)  #设备是cuda:0，即GPU，如果没有GPU则是cpu\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=12, micro=3, releaselevel='final', serial=0)\n",
      "matplotlib 3.10.0\n",
      "numpy 1.26.4\n",
      "pandas 2.2.3\n",
      "sklearn 1.6.1\n",
      "torch 2.6.0+cu126\n",
      "cuda:0\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T14:27:36.900058Z",
     "start_time": "2025-02-21T14:27:35.229167Z"
    }
   },
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# fashion_mnist图像分类数据集\n",
    "train_ds = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_ds = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "# torchvision 数据集里没有提供训练集和验证集的划分\n",
    "# 当然也可以用 torch.utils.data.Dataset 实现人为划分"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T14:27:36.905189Z",
     "start_time": "2025-02-21T14:27:36.900058Z"
    }
   },
   "cell_type": "code",
   "source": "type(train_ds)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.FashionMNIST"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T14:27:36.909365Z",
     "start_time": "2025-02-21T14:27:36.906195Z"
    }
   },
   "source": [
    "# 从数据集到dataloader\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(test_ds, batch_size=32, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "# 查看数据\n",
    "for datas, labels in train_loader:\n",
    "    print(datas.shape)\n",
    "    print(labels.shape)\n",
    "    break\n",
    "#查看val_loader\n",
    "for datas, labels in val_loader:\n",
    "    print(datas.shape)\n",
    "    print(labels.shape)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-21T14:27:36.928442Z",
     "start_time": "2025-02-21T14:27:36.910372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T14:27:36.936225Z",
     "start_time": "2025-02-21T14:27:36.929446Z"
    }
   },
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 300),  # in_features=784, out_features=300\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(300, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape [batch size, 1, 28, 28]\n",
    "        x = self.flatten(x)  \n",
    "        # 展平后 x.shape [batch size, 28 * 28]\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        # logits.shape [batch size, 10]\n",
    "        return logits\n",
    "    \n",
    "model = NeuralNetwork()"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练\n",
    "\n",
    "pytorch的训练需要自行实现，包括\n",
    "1. 定义损失函数\n",
    "2. 定义优化器\n",
    "3. 定义训练步\n",
    "4. 训练"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T14:27:37.116262Z",
     "start_time": "2025-02-21T14:27:36.936225Z"
    }
   },
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluating(model, dataloader, loss_fct):\n",
    "    loss_list = []\n",
    "    pred_list = []\n",
    "    label_list = []\n",
    "    for datas, labels in dataloader:\n",
    "        #datas.shape [batch size, 1, 28, 28]\n",
    "        #labels.shape [batch size]\n",
    "        datas = datas.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # 前向计算\n",
    "        logits = model(datas)\n",
    "        loss = loss_fct(logits, labels)         # 验证集损失\n",
    "        loss_list.append(loss.item()) # tensor.item() 获取tensor的数值，loss是只有一个元素的tensor\n",
    "        \n",
    "        preds = logits.argmax(axis=-1)    # 验证集预测, axis=-1 表示最后一个维度,因为logits.shape [batch size, 10]，所以axis=-1表示对最后一个维度求argmax，即对每个样本的10个类别的概率求argmax，得到最大概率的类别, preds.shape [batch size]\n",
    "        pred_list.extend(preds.cpu().numpy().tolist()) # tensor转numpy，再转list\n",
    "        label_list.extend(labels.cpu().numpy().tolist())\n",
    "        \n",
    "    acc = accuracy_score(label_list, pred_list) # 验证集准确率\n",
    "    return np.mean(loss_list), acc # 返回验证集平均损失和准确率\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard 可视化\n",
    "\n",
    "pip install tensorboard\n",
    "训练过程中可以使用如下命令启动tensorboard服务。注意使用绝对路径，否则会报错\n",
    "\n",
    "```shell\n",
    " tensorboard  --logdir=\"D:\\BaiduSyncdisk\\pytorch\\chapter_2_torch\\runs\" --host 0.0.0.0 --port 8848\n",
    "```"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "在命令行where tensorboard才可以用"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T14:27:50.850757Z",
     "start_time": "2025-02-21T14:27:37.117266Z"
    }
   },
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "class TensorBoardCallback:\n",
    "    def __init__(self, log_dir, flush_secs=10):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            log_dir (str): dir to write log.\n",
    "            flush_secs (int, optional): write to dsk each flush_secs seconds. Defaults to 10.\n",
    "        \"\"\"\n",
    "        self.writer = SummaryWriter(log_dir=log_dir, flush_secs=flush_secs) # 实例化SummaryWriter, log_dir是log存放路径，flush_secs是每隔多少秒写入磁盘\n",
    "\n",
    "    def draw_model(self, model, input_shape):#graphs\n",
    "        self.writer.add_graph(model, input_to_model=torch.randn(input_shape)) # 画模型图\n",
    "        \n",
    "    def add_loss_scalars(self, step, loss, val_loss):\n",
    "        self.writer.add_scalars(\n",
    "            main_tag=\"training/loss\", \n",
    "            tag_scalar_dict={\"loss\": loss, \"val_loss\": val_loss},\n",
    "            global_step=step,\n",
    "            ) # 画loss曲线, main_tag是主tag，tag_scalar_dict是子tag，global_step是步数\n",
    "        \n",
    "    def add_acc_scalars(self, step, acc, val_acc):\n",
    "        self.writer.add_scalars(\n",
    "            main_tag=\"training/accuracy\",\n",
    "            tag_scalar_dict={\"accuracy\": acc, \"val_accuracy\": val_acc},\n",
    "            global_step=step,\n",
    "        ) # 画acc曲线, main_tag是主tag，tag_scalar_dict是子tag，global_step是步数\n",
    "        \n",
    "    def add_lr_scalars(self, step, learning_rate):\n",
    "        self.writer.add_scalars(\n",
    "            main_tag=\"training/learning_rate\",\n",
    "            tag_scalar_dict={\"learning_rate\": learning_rate},\n",
    "            global_step=step,\n",
    "        ) # 画lr曲线, main_tag是主tag，tag_scalar_dict是子tag，global_step是步数\n",
    "    \n",
    "    def __call__(self, step, **kwargs):\n",
    "        # add loss,把loss，val_loss取掉，画loss曲线\n",
    "        loss = kwargs.pop(\"loss\", None)\n",
    "        val_loss = kwargs.pop(\"val_loss\", None)\n",
    "        if loss is not None and val_loss is not None:\n",
    "            self.add_loss_scalars(step, loss, val_loss) # 画loss曲线\n",
    "        # add acc\n",
    "        acc = kwargs.pop(\"acc\", None)\n",
    "        val_acc = kwargs.pop(\"val_acc\", None)\n",
    "        if acc is not None and val_acc is not None:\n",
    "            self.add_acc_scalars(step, acc, val_acc) # 画acc曲线\n",
    "        # add lr\n",
    "        learning_rate = kwargs.pop(\"lr\", None)\n",
    "        if learning_rate is not None:\n",
    "            self.add_lr_scalars(step, learning_rate) # 画lr曲线\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Best\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T14:27:50.856475Z",
     "start_time": "2025-02-21T14:27:50.851761Z"
    }
   },
   "source": [
    "class SaveCheckpointsCallback:\n",
    "    def __init__(self, save_dir, save_step=500, save_best_only=True):\n",
    "        \"\"\"\n",
    "        Save checkpoints each save_epoch epoch. \n",
    "        We save checkpoint by epoch in this implementation.\n",
    "        Usually, training scripts with pytorch evaluating model and save checkpoint by step.\n",
    "\n",
    "        Args:\n",
    "            save_dir (str): dir to save checkpoint\n",
    "            save_epoch (int, optional): the frequency to save checkpoint. Defaults to 1.\n",
    "            save_best_only (bool, optional): If True, only save the best model or save each model at every epoch.\n",
    "        \"\"\"\n",
    "        self.save_dir = save_dir # 保存路径\n",
    "        self.save_step = save_step # 保存步数\n",
    "        self.save_best_only = save_best_only # 是否只保存最好的模型\n",
    "        self.best_metrics = -1 # 最好的指标，指标不可能为负数，所以初始化为-1\n",
    "        \n",
    "        # mkdir\n",
    "        if not os.path.exists(self.save_dir): # 如果不存在保存路径，则创建\n",
    "            os.mkdir(self.save_dir)\n",
    "        \n",
    "    def __call__(self, step, state_dict, metric=None):\n",
    "        if step % self.save_step > 0: #每隔save_step步保存一次\n",
    "            return\n",
    "        \n",
    "        if self.save_best_only:\n",
    "            assert metric is not None # 必须传入metric\n",
    "            if metric >= self.best_metrics:\n",
    "                # save checkpoints\n",
    "                torch.save(state_dict, os.path.join(self.save_dir, \"best.ckpt\")) # 保存最好的模型，覆盖之前的模型，不保存step，只保存state_dict，即模型参数，不保存优化器参数\n",
    "                # update best metrics\n",
    "                self.best_metrics = metric\n",
    "        else:\n",
    "            torch.save(state_dict, os.path.join(self.save_dir, f\"{step}.ckpt\")) # 保存每个step的模型，不覆盖之前的模型，保存step，保存state_dict，即模型参数，不保存优化器参数\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stop"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T14:27:50.861542Z",
     "start_time": "2025-02-21T14:27:50.857479Z"
    }
   },
   "source": [
    "class EarlyStopCallback:\n",
    "    def __init__(self, patience=5, min_delta=0.01):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            patience (int, optional): Number of epochs with no improvement after which training will be stopped.. Defaults to 5.\n",
    "            min_delta (float, optional): Minimum change in the monitored quantity to qualify as an improvement, i.e. an absolute \n",
    "                change of less than min_delta, will count as no improvement. Defaults to 0.01.\n",
    "        \"\"\"\n",
    "        self.patience = patience # 多少个step没有提升就停止训练\n",
    "        self.min_delta = min_delta # 最小的提升幅度\n",
    "        self.best_metric = -1\n",
    "        self.counter = 0 # 计数器，记录多少个step没有提升\n",
    "        \n",
    "    def __call__(self, metric):\n",
    "        if metric >= self.best_metric + self.min_delta:#用准确率\n",
    "            # update best metric\n",
    "            self.best_metric = metric\n",
    "            # reset counter \n",
    "            self.counter = 0\n",
    "        else: \n",
    "            self.counter += 1 # 计数器加1，下面的patience判断用到\n",
    "            \n",
    "    @property #使用@property装饰器，使得 对象.early_stop可以调用，不需要()\n",
    "    def early_stop(self):\n",
    "        return self.counter >= self.patience\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "500*32*5"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-21T14:27:50.866295Z",
     "start_time": "2025-02-21T14:27:50.862549Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T14:27:50.873194Z",
     "start_time": "2025-02-21T14:27:50.866295Z"
    }
   },
   "source": [
    "# 训练\n",
    "def training(\n",
    "    model, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    epoch, \n",
    "    loss_fct, \n",
    "    optimizer, \n",
    "    tensorboard_callback=None,\n",
    "    save_ckpt_callback=None,\n",
    "    early_stop_callback=None,\n",
    "    eval_step=500,\n",
    "    ):\n",
    "    record_dict = {\n",
    "        \"train\": [],\n",
    "        \"val\": []\n",
    "    }\n",
    "    \n",
    "    global_step = 0\n",
    "    model.train()\n",
    "    with tqdm(total=epoch * len(train_loader)) as pbar:\n",
    "        for epoch_id in range(epoch):\n",
    "            # training\n",
    "            for datas, labels in train_loader:\n",
    "                datas = datas.to(device) # 数据放到device上\n",
    "                labels = labels.to(device) # 标签放到device上\n",
    "                # 梯度清空\n",
    "                optimizer.zero_grad()\n",
    "                # 模型前向计算\n",
    "                logits = model(datas)\n",
    "                # 计算损失\n",
    "                loss = loss_fct(logits, labels)\n",
    "                # 梯度回传，计算梯度，更新参数，这里是更新模型参数\n",
    "                loss.backward()\n",
    "                # 调整优化器，包括学习率的变动等\n",
    "                optimizer.step()\n",
    "                preds = logits.argmax(axis=-1)\n",
    "            \n",
    "                acc = accuracy_score(labels.cpu().numpy(), preds.cpu().numpy())    \n",
    "                loss = loss.cpu().item()\n",
    "                # record\n",
    "                \n",
    "                record_dict[\"train\"].append({\n",
    "                    \"loss\": loss, \"acc\": acc, \"step\": global_step\n",
    "                })\n",
    "                \n",
    "                # evaluating\n",
    "                if global_step % eval_step == 0:\n",
    "                    model.eval()  # 切换到验证集模式\n",
    "                    val_loss, val_acc = evaluating(model, val_loader, loss_fct)\n",
    "                    record_dict[\"val\"].append({\n",
    "                        \"loss\": val_loss, \"acc\": val_acc, \"step\": global_step\n",
    "                    })\n",
    "                    model.train() # 切换回训练集模式\n",
    "                    \n",
    "                    # 1. 使用 tensorboard 可视化\n",
    "                    if tensorboard_callback is not None:\n",
    "                        tensorboard_callback(\n",
    "                            global_step, \n",
    "                            loss=loss, val_loss=val_loss,\n",
    "                            acc=acc, val_acc=val_acc,\n",
    "                            lr=optimizer.param_groups[0][\"lr\"], # 取出当前学习率\n",
    "                            )\n",
    "                    \n",
    "                    # 2. 保存模型权重 save model checkpoint\n",
    "                    if save_ckpt_callback is not None:\n",
    "                        save_ckpt_callback(global_step, model.state_dict(), metric=val_acc) # 保存最好的模型，覆盖之前的模型，保存step，保存state_dict,通过metric判断是否保存最好的模型\n",
    "\n",
    "                    # 3. 早停 Early Stop\n",
    "                    if early_stop_callback is not None:\n",
    "                        early_stop_callback(val_acc) # 验证集准确率不再提升，则停止训练\n",
    "                        if early_stop_callback.early_stop:# 验证集准确率不再提升，则停止训练\n",
    "                            print(f\"Early stop at epoch {epoch_id} / global_step {global_step}\")\n",
    "                            return record_dict\n",
    "                    \n",
    "                # udate step\n",
    "                global_step += 1\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix({\"epoch\": epoch_id})\n",
    "        \n",
    "    return record_dict"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "epoch = 100\n",
    "\n",
    "model = NeuralNetwork()\n",
    "\n",
    "# 1. 定义损失函数 采用MSE损失\n",
    "loss_fct = nn.CrossEntropyLoss()\n",
    "# 2. 定义优化器 采用SGD\n",
    "# Optimizers specified in the torch.optim package\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# 1. tensorboard 可视化\n",
    "tensorboard_callback = TensorBoardCallback(\"runs\")\n",
    "tensorboard_callback.draw_model(model, [1, 28, 28])\n",
    "# 2. save best\n",
    "save_ckpt_callback = SaveCheckpointsCallback(\"checkpoints\", save_best_only=True)\n",
    "# 3. early stop\n",
    "early_stop_callback = EarlyStopCallback(patience=10)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-21T14:27:50.990841Z",
     "start_time": "2025-02-21T14:27:50.874200Z"
    }
   },
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "list(model.parameters())[1] #可学习的模型参数"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-21T14:27:51.005842Z",
     "start_time": "2025-02-21T14:27:50.992847Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 3.0885e-03, -1.4995e-02, -2.8202e-02, -2.1357e-02, -9.6099e-03,\n",
       "         1.2764e-02,  8.1250e-03, -2.8291e-02,  9.5495e-03, -3.5639e-02,\n",
       "        -3.3872e-02,  1.4156e-02, -3.4921e-02,  1.5818e-02,  8.0202e-03,\n",
       "        -5.9029e-03, -2.4263e-02,  6.9760e-04, -1.5900e-02, -1.9275e-02,\n",
       "         1.4463e-02, -3.3015e-02, -1.1214e-02, -1.8422e-02,  1.3731e-02,\n",
       "         2.6130e-02, -3.3491e-03, -2.1681e-02, -4.0552e-03,  1.6143e-02,\n",
       "         3.5378e-02,  7.2745e-03, -2.0284e-02,  4.5335e-03,  2.2471e-02,\n",
       "        -1.0175e-02,  3.4367e-02,  6.9675e-04,  1.2150e-02,  2.1196e-02,\n",
       "        -5.3604e-03, -1.1999e-02, -2.4515e-02, -2.6637e-02,  2.8006e-02,\n",
       "         3.1979e-02,  2.8860e-02, -8.6640e-03,  2.4064e-02,  2.1353e-02,\n",
       "         9.5615e-03, -2.2317e-02,  2.1351e-02,  2.4167e-02, -1.8270e-02,\n",
       "         1.2695e-02,  1.1744e-02,  2.8897e-02,  7.9796e-03,  3.0914e-02,\n",
       "        -1.3931e-02, -8.7428e-03,  1.1286e-03, -2.7419e-02, -2.3668e-02,\n",
       "         1.0779e-02,  5.8940e-03, -3.1938e-02, -2.1601e-03,  2.8723e-02,\n",
       "         4.8817e-03, -3.4183e-02, -2.8918e-02, -2.6247e-02, -2.0461e-02,\n",
       "        -2.4608e-02, -2.6346e-02, -2.7478e-02,  2.8223e-05,  2.5983e-02,\n",
       "         2.9652e-02, -8.5051e-03, -1.5980e-03,  2.4881e-02,  3.3403e-02,\n",
       "         9.3758e-03, -1.7788e-02,  2.8297e-02, -2.6633e-02, -2.4065e-02,\n",
       "        -2.3644e-02, -2.9084e-02, -6.5303e-03,  2.0463e-02, -1.8192e-02,\n",
       "         2.5792e-02, -6.8662e-03, -1.2717e-02, -1.4718e-02, -4.7218e-03,\n",
       "        -2.3424e-02, -6.6979e-03, -1.2457e-02,  2.4461e-02,  2.6312e-02,\n",
       "        -1.4922e-02,  3.4489e-02,  6.1850e-03, -1.1935e-02,  6.7217e-03,\n",
       "        -2.6545e-02,  1.2743e-02, -3.4067e-02,  1.1893e-02,  3.3202e-02,\n",
       "        -1.9879e-02, -3.0157e-02,  3.4164e-02,  3.0677e-02,  3.0284e-02,\n",
       "        -1.9560e-03, -4.5884e-03, -2.9456e-03, -2.5990e-02,  1.3220e-02,\n",
       "        -2.6680e-02, -3.2072e-02,  2.4356e-02, -2.0743e-02, -1.4608e-02,\n",
       "         1.2896e-02,  3.2678e-02,  1.7291e-02,  1.9257e-02,  4.5859e-03,\n",
       "        -2.0815e-02, -3.3000e-02,  3.2349e-02, -4.9154e-03, -2.0991e-02,\n",
       "         2.9919e-02,  4.0706e-03,  7.5247e-03,  3.2567e-03, -2.0675e-02,\n",
       "         4.5286e-03, -2.2490e-02, -1.8043e-02, -3.4993e-02,  2.6076e-02,\n",
       "        -8.5931e-03,  8.8617e-03, -2.0592e-02,  3.1636e-02, -1.3828e-02,\n",
       "         1.5317e-02, -1.2010e-02, -1.5266e-02, -1.0866e-02,  2.0699e-02,\n",
       "         3.4451e-02,  2.4687e-02,  8.8059e-03,  2.0517e-02,  1.0955e-02,\n",
       "         1.5162e-02,  1.2474e-03, -3.6717e-04,  7.9652e-03, -2.9330e-02,\n",
       "        -5.5538e-03, -1.7725e-02,  1.0790e-02, -5.4523e-03,  1.7836e-02,\n",
       "         6.2989e-04, -3.2872e-02,  2.3164e-02,  1.5283e-02,  1.9191e-02,\n",
       "         2.8062e-02, -1.9985e-02, -5.6397e-03, -1.7450e-02,  1.4513e-02,\n",
       "        -1.3584e-02, -3.3038e-02,  2.1947e-02, -9.1188e-03,  2.3933e-02,\n",
       "         1.7840e-02, -1.9969e-02, -3.2891e-02,  1.0527e-02, -2.4707e-03,\n",
       "         2.7814e-02,  1.7502e-02,  1.5027e-02, -1.2900e-02,  1.1422e-02,\n",
       "        -2.9412e-02, -1.0680e-02, -2.0727e-02,  1.3848e-02,  1.7709e-02,\n",
       "         2.0867e-02,  1.7389e-02,  4.2554e-03,  3.4465e-02,  2.3306e-02,\n",
       "         1.8018e-02, -3.0737e-02, -2.1272e-02,  6.6712e-03,  2.4491e-03,\n",
       "        -1.5373e-03, -2.8769e-02,  1.7170e-02, -9.3282e-03, -1.0963e-02,\n",
       "        -1.4905e-02, -2.9357e-02,  1.4136e-02,  1.7668e-02,  1.9125e-02,\n",
       "        -1.1268e-02, -6.5779e-03, -1.6865e-03, -2.3282e-02,  9.1619e-04,\n",
       "        -3.2245e-02, -8.3082e-03,  2.3524e-02,  3.4525e-02, -2.5101e-02,\n",
       "        -2.8374e-03, -1.2159e-02, -3.0680e-02, -1.6511e-03,  1.8119e-02,\n",
       "        -3.1355e-02, -1.7418e-02,  2.4688e-02,  6.7558e-03, -2.9570e-02,\n",
       "         1.5859e-02,  1.5940e-02, -4.5853e-03, -2.8494e-02,  1.4867e-02,\n",
       "        -2.5300e-02, -5.7823e-03,  9.5829e-03,  2.4604e-02,  1.5682e-02,\n",
       "         2.2027e-02, -2.0704e-02, -3.1900e-02,  3.3036e-02,  2.4144e-02,\n",
       "        -3.2308e-02, -2.5586e-02, -2.1393e-02, -2.3388e-03,  1.5985e-02,\n",
       "        -1.9573e-02, -3.1448e-02,  1.1828e-02, -7.8960e-03,  1.7702e-02,\n",
       "         3.5502e-02,  2.5537e-02, -1.8066e-03,  3.2946e-02,  1.8559e-02,\n",
       "         3.5494e-03, -3.1666e-02,  1.5678e-02, -3.3575e-02,  3.1774e-02,\n",
       "        -1.4051e-02, -2.2380e-02, -2.6514e-02, -1.6830e-02, -3.1369e-02,\n",
       "         8.6644e-03, -1.9612e-02, -8.1498e-03,  1.8018e-02,  4.8405e-03,\n",
       "         2.3829e-02,  1.2685e-02, -1.6253e-02,  3.0783e-02, -3.3480e-02,\n",
       "         1.1359e-02,  2.7716e-02, -7.4252e-03, -3.9924e-04, -1.6861e-02],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": "model.state_dict().keys() #模型参数名字",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-21T14:27:51.011643Z",
     "start_time": "2025-02-21T14:27:51.006849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['linear_relu_stack.0.weight', 'linear_relu_stack.0.bias', 'linear_relu_stack.2.weight', 'linear_relu_stack.2.bias', 'linear_relu_stack.4.weight', 'linear_relu_stack.4.bias'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "model = model.to(device) # 放到device上\n",
    "record = training(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    epoch,\n",
    "    loss_fct,\n",
    "    optimizer,\n",
    "    tensorboard_callback=tensorboard_callback,\n",
    "    save_ckpt_callback=save_ckpt_callback,\n",
    "    early_stop_callback=early_stop_callback,\n",
    "    eval_step=1000\n",
    "    )\n",
    "#没有进度条，是因为pycharm本身jupyter的问题"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-21T14:31:08.131273Z",
     "start_time": "2025-02-21T14:31:07.196548Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/187500 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d6737e8d2c6e42d4bbdaaf4651c41d84"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "runs is not a directory",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFailedPreconditionError\u001B[0m                   Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mto(device) \u001B[38;5;66;03m# 放到device上\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m record \u001B[38;5;241m=\u001B[39m \u001B[43mtraining\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mloss_fct\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensorboard_callback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensorboard_callback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43msave_ckpt_callback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msave_ckpt_callback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43mearly_stop_callback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mearly_stop_callback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_step\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1000\u001B[39;49m\n\u001B[0;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m#没有进度条，是因为pycharm本身jupyter的问题\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[12], line 58\u001B[0m, in \u001B[0;36mtraining\u001B[1;34m(model, train_loader, val_loader, epoch, loss_fct, optimizer, tensorboard_callback, save_ckpt_callback, early_stop_callback, eval_step)\u001B[0m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;66;03m# 1. 使用 tensorboard 可视化\u001B[39;00m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tensorboard_callback \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 58\u001B[0m     \u001B[43mtensorboard_callback\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     59\u001B[0m \u001B[43m        \u001B[49m\u001B[43mglobal_step\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m     60\u001B[0m \u001B[43m        \u001B[49m\u001B[43mloss\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loss\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_loss\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     61\u001B[0m \u001B[43m        \u001B[49m\u001B[43macc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43macc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_acc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_acc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     62\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_groups\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# 取出当前学习率\u001B[39;49;00m\n\u001B[0;32m     63\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;66;03m# 2. 保存模型权重 save model checkpoint\u001B[39;00m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m save_ckpt_callback \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "Cell \u001B[1;32mIn[8], line 42\u001B[0m, in \u001B[0;36mTensorBoardCallback.__call__\u001B[1;34m(self, step, **kwargs)\u001B[0m\n\u001B[0;32m     40\u001B[0m val_loss \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m     41\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m loss \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m val_loss \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 42\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_loss_scalars\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loss\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# 画loss曲线\u001B[39;00m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;66;03m# add acc\u001B[39;00m\n\u001B[0;32m     44\u001B[0m acc \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124macc\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "Cell \u001B[1;32mIn[8], line 17\u001B[0m, in \u001B[0;36mTensorBoardCallback.add_loss_scalars\u001B[1;34m(self, step, loss, val_loss)\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21madd_loss_scalars\u001B[39m(\u001B[38;5;28mself\u001B[39m, step, loss, val_loss):\n\u001B[1;32m---> 17\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwriter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_scalars\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmain_tag\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtraining/loss\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtag_scalar_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mloss\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mval_loss\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loss\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[43m        \u001B[49m\u001B[43mglobal_step\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Program Files\\Python\\Lib\\site-packages\\torch\\utils\\tensorboard\\writer.py:421\u001B[0m, in \u001B[0;36mSummaryWriter.add_scalars\u001B[1;34m(self, main_tag, tag_scalar_dict, global_step, walltime)\u001B[0m\n\u001B[0;32m    419\u001B[0m     fw \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mall_writers[fw_tag]\n\u001B[0;32m    420\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 421\u001B[0m     fw \u001B[38;5;241m=\u001B[39m \u001B[43mFileWriter\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    422\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfw_tag\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_queue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflush_secs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfilename_suffix\u001B[49m\n\u001B[0;32m    423\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    424\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mall_writers[fw_tag] \u001B[38;5;241m=\u001B[39m fw\n\u001B[0;32m    425\u001B[0m fw\u001B[38;5;241m.\u001B[39madd_summary(scalar(main_tag, scalar_value), global_step, walltime)\n",
      "File \u001B[1;32mD:\\Program Files\\Python\\Lib\\site-packages\\torch\\utils\\tensorboard\\writer.py:76\u001B[0m, in \u001B[0;36mFileWriter.__init__\u001B[1;34m(self, log_dir, max_queue, flush_secs, filename_suffix)\u001B[0m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;66;03m# Sometimes PosixPath is passed in and we need to coerce it to\u001B[39;00m\n\u001B[0;32m     72\u001B[0m \u001B[38;5;66;03m# a string in all cases\u001B[39;00m\n\u001B[0;32m     73\u001B[0m \u001B[38;5;66;03m# TODO: See if we can remove this in the future if we are\u001B[39;00m\n\u001B[0;32m     74\u001B[0m \u001B[38;5;66;03m# actually the ones passing in a PosixPath\u001B[39;00m\n\u001B[0;32m     75\u001B[0m log_dir \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(log_dir)\n\u001B[1;32m---> 76\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevent_writer \u001B[38;5;241m=\u001B[39m \u001B[43mEventFileWriter\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     77\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlog_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_queue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflush_secs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename_suffix\u001B[49m\n\u001B[0;32m     78\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Program Files\\Python\\Lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py:72\u001B[0m, in \u001B[0;36mEventFileWriter.__init__\u001B[1;34m(self, logdir, max_queue_size, flush_secs, filename_suffix)\u001B[0m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Creates a `EventFileWriter` and an event file to write to.\u001B[39;00m\n\u001B[0;32m     58\u001B[0m \n\u001B[0;32m     59\u001B[0m \u001B[38;5;124;03mOn construction the summary writer creates a new event file in `logdir`.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     69\u001B[0m \u001B[38;5;124;03m    pending events and summaries to disk.\u001B[39;00m\n\u001B[0;32m     70\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_logdir \u001B[38;5;241m=\u001B[39m logdir\n\u001B[1;32m---> 72\u001B[0m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgfile\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmakedirs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlogdir\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     73\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_file_name \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     74\u001B[0m     os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\n\u001B[0;32m     75\u001B[0m         logdir,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     84\u001B[0m     \u001B[38;5;241m+\u001B[39m filename_suffix\n\u001B[0;32m     85\u001B[0m )  \u001B[38;5;66;03m# noqa E128\u001B[39;00m\n\u001B[0;32m     86\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_general_file_writer \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mio\u001B[38;5;241m.\u001B[39mgfile\u001B[38;5;241m.\u001B[39mGFile(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_file_name, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\Program Files\\Python\\Lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py:513\u001B[0m, in \u001B[0;36mrecursive_create_dir_v2\u001B[1;34m(path)\u001B[0m\n\u001B[0;32m    501\u001B[0m \u001B[38;5;129m@tf_export\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mio.gfile.makedirs\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    502\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mrecursive_create_dir_v2\u001B[39m(path):\n\u001B[0;32m    503\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Creates a directory and all parent/intermediate directories.\u001B[39;00m\n\u001B[0;32m    504\u001B[0m \n\u001B[0;32m    505\u001B[0m \u001B[38;5;124;03m  It succeeds if path already exists and is writable.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    511\u001B[0m \u001B[38;5;124;03m    errors.OpError: If the operation fails.\u001B[39;00m\n\u001B[0;32m    512\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[1;32m--> 513\u001B[0m   \u001B[43m_pywrap_file_io\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mRecursivelyCreateDir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcompat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath_to_bytes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mFailedPreconditionError\u001B[0m: runs is not a directory"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "source": [
    "#帮我写个enumerate例子\n",
    "for i, item in enumerate([\"a\", \"b\", \"c\"]):\n",
    "    print(i, item)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-21T14:30:54.727356Z",
     "start_time": "2025-02-21T14:30:54.724826Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 a\n",
      "1 b\n",
      "2 c\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T14:31:16.271484Z",
     "start_time": "2025-02-21T14:31:16.258873Z"
    }
   },
   "cell_type": "code",
   "source": "record",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'record' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[22], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mrecord\u001B[49m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'record' is not defined"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T14:31:33.710617Z",
     "start_time": "2025-02-21T14:31:33.695956Z"
    }
   },
   "source": [
    "#画线要注意的是损失是不一定在零到1之间的\n",
    "def plot_learning_curves(record_dict, sample_step=500):\n",
    "    # build DataFrame\n",
    "    train_df = pd.DataFrame(record_dict[\"train\"]).set_index(\"step\").iloc[::sample_step]\n",
    "    val_df = pd.DataFrame(record_dict[\"val\"]).set_index(\"step\")\n",
    "    print(train_df.head())\n",
    "    print(val_df.head())\n",
    "    # plot\n",
    "    fig_num = len(train_df.columns) #因为有loss和acc两个指标，所以画个子图\n",
    "    fig, axs = plt.subplots(1, fig_num, figsize=(5 * fig_num, 5)) #fig_num个子图，figsize是子图大小\n",
    "    for idx, item in enumerate(train_df.columns):    \n",
    "        #index是步数，item是指标名字\n",
    "        axs[idx].plot(train_df.index, train_df[item], label=f\"train_{item}\")\n",
    "        axs[idx].plot(val_df.index, val_df[item], label=f\"val_{item}\")\n",
    "        axs[idx].grid()\n",
    "        axs[idx].legend()\n",
    "        x_data=range(0, train_df.index[-1], 5000) #每隔5000步标出一个点\n",
    "        axs[idx].set_xticks(x_data)\n",
    "        axs[idx].set_xticklabels(map(lambda x: f\"{int(x/1000)}k\", x_data)) #map生成labal\n",
    "        axs[idx].set_xlabel(\"step\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_learning_curves(record, sample_step=500)  #横坐标是 steps"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'record' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[23], line 24\u001B[0m\n\u001B[0;32m     20\u001B[0m         axs[idx]\u001B[38;5;241m.\u001B[39mset_xlabel(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstep\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     22\u001B[0m     plt\u001B[38;5;241m.\u001B[39mshow()\n\u001B[1;32m---> 24\u001B[0m plot_learning_curves(\u001B[43mrecord\u001B[49m, sample_step\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m500\u001B[39m)  \u001B[38;5;66;03m#横坐标是 steps\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'record' is not defined"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评估"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model = NeuralNetwork() #上线时加载模型\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-21T14:31:39.068365Z",
     "start_time": "2025-02-21T14:31:39.054812Z"
    }
   },
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T14:31:40.742663Z",
     "start_time": "2025-02-21T14:31:40.682924Z"
    }
   },
   "source": [
    "# dataload for evaluating\n",
    "#模型保存有两种情况，一种是模型结构和模型参数都保存，一种是只保存模型参数，这里是只保存模型参数，所以需要加上weights_only=True\n",
    "# load checkpoints\n",
    "model.load_state_dict(torch.load(\"checkpoints/best.ckpt\", weights_only=True,map_location=\"cpu\"))\n",
    "\n",
    "model.eval()\n",
    "loss, acc = evaluating(model, val_loader, loss_fct)\n",
    "print(f\"loss:     {loss:.4f}\\naccuracy: {acc:.4f}\")"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'checkpoints/best.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[25], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# dataload for evaluating\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m#模型保存有两种情况，一种是模型结构和模型参数都保存，一种是只保存模型参数，这里是只保存模型参数，所以需要加上weights_only=True\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# load checkpoints\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m model\u001B[38;5;241m.\u001B[39mload_state_dict(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcheckpoints/best.ckpt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43mmap_location\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcpu\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[0;32m      6\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n\u001B[0;32m      7\u001B[0m loss, acc \u001B[38;5;241m=\u001B[39m evaluating(model, val_loader, loss_fct)\n",
      "File \u001B[1;32mD:\\Program Files\\Python\\Lib\\site-packages\\torch\\serialization.py:1425\u001B[0m, in \u001B[0;36mload\u001B[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[0;32m   1422\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m pickle_load_args\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m   1423\u001B[0m     pickle_load_args[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1425\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_open_file_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_file:\n\u001B[0;32m   1426\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_zipfile(opened_file):\n\u001B[0;32m   1427\u001B[0m         \u001B[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001B[39;00m\n\u001B[0;32m   1428\u001B[0m         \u001B[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001B[39;00m\n\u001B[0;32m   1429\u001B[0m         \u001B[38;5;66;03m# reset back to the original position.\u001B[39;00m\n\u001B[0;32m   1430\u001B[0m         orig_position \u001B[38;5;241m=\u001B[39m opened_file\u001B[38;5;241m.\u001B[39mtell()\n",
      "File \u001B[1;32mD:\\Program Files\\Python\\Lib\\site-packages\\torch\\serialization.py:751\u001B[0m, in \u001B[0;36m_open_file_like\u001B[1;34m(name_or_buffer, mode)\u001B[0m\n\u001B[0;32m    749\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_open_file_like\u001B[39m(name_or_buffer, mode):\n\u001B[0;32m    750\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_path(name_or_buffer):\n\u001B[1;32m--> 751\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_open_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    752\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    753\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n",
      "File \u001B[1;32mD:\\Program Files\\Python\\Lib\\site-packages\\torch\\serialization.py:732\u001B[0m, in \u001B[0;36m_open_file.__init__\u001B[1;34m(self, name, mode)\u001B[0m\n\u001B[0;32m    731\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, mode):\n\u001B[1;32m--> 732\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'checkpoints/best.ckpt'"
     ]
    }
   ],
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
